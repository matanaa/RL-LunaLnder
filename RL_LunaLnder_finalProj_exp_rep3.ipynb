{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_LunaLnder_finalProj exp_rep2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HND9HYhOE89T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-cVn8qQKtJq"
      },
      "source": [
        "Based on the following links to create this notebook:\n",
        "\n",
        "https://colab.research.google.com/drive/18LdlDDT87eb8cCTHZsXyS9ksQPzL3i6H\n",
        "\n",
        "https://colab.research.google.com/drive/1tug_bpg8RwrFOI8C6Ed-zo0OgD3yfnWy#scrollTo=bhsj7BTPHepg\n",
        "\n",
        "https://colab.research.google.com/drive/1tug_bpg8RwrFOI8C6Ed-zo0OgD3yfnWy\n",
        "\n",
        "\n",
        "To run Gym, you have to install prerequisites like xvbf,opengl & other python-dev packages using the following codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14NwgxVmX-Og"
      },
      "source": [
        "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmtbAjPPKiFw",
        "outputId": "43de22e1-b607-4f8a-b695-1b95410f5b34"
      },
      "source": [
        "!pip install gym  torch\n",
        "!apt-get install python-opengl ffmpeg -y \n",
        "!apt install xvfb -y \n",
        "!pip install pyvirtualdisplay  \n",
        "!pip install piglet \n",
        "!pip install gym[box2d] \n",
        "!pip install tensorflow \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.7.1+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.1)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: piglet in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: piglet-templates in /usr/local/lib/python3.7/dist-packages (from piglet) (1.1.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (20.3.0)\n",
            "Requirement already satisfied: Parsley in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.3)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.1.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (0.36.2)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.3.0)\n",
            "Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (2.3.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]) (0.16.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (54.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2LD1gwzX-Oh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7fbd53c-cea1-470a-c524-7fea8d719e1c"
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fcbc9eed4d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_hxdz4ALVQ3"
      },
      "source": [
        "# This code creates a virtual display to draw game images on. \n",
        "# If you are running locally, just ignore it\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1GqN0iRLaZk"
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) # error only\n",
        "# import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "from collections import namedtuple"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILbriB_oLn5T"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env\n",
        "\n",
        "def make_noise():\n",
        "    mu, sigma = 0, 0.05 # mean and standard deviation\n",
        "    return np.random.normal(mu, sigma, 1)[0]\n",
        "\n",
        "def plot(frame_idx, rewards, losses):\n",
        "#     clear_output(True)\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.subplot(131)\n",
        "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
        "    plt.plot(rewards)\n",
        "    plt.subplot(132)\n",
        "    plt.title('loss')\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SERZbDJqX-Oj"
      },
      "source": [
        "# My Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU2kLfDwX-Ok"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pickle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyVG3_erX-Ok"
      },
      "source": [
        "class defaultActions:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.main = [[0 , \"Main off\"],\n",
        "                     [0.5 ,\"Main slow\"],\n",
        "#                      [0.75 , \"Main meduim\"],\n",
        "                     [1    , \"Main strong\"]\n",
        "                    ]\n",
        "        self.left_right = [\n",
        "                        [0, \"Left Right off\"],\n",
        "#                         [-0.5 , \"Left slow\"],\n",
        "#                         [-0.75  , \"Left meduim\"],\n",
        "                        [-1 , \"Left strong\"],\n",
        "                        \n",
        "#                         [0.5 , \"Right slow\"],\n",
        "#                         [0.75  , \"Right meduim\"],\n",
        "                        [1 , \"Right strong\"],\n",
        "                        ]\n",
        "        self.all_actions = {}\n",
        "        i = 0  \n",
        "        for main_eng in self.main:\n",
        "            for sec_eng in self.left_right:\n",
        "#                 print (f\"a{i},act:[{main_eng[0]},{sec_eng[0]},{main_eng[1]} {sec_eng[1]}]\")\n",
        "                self.all_actions[i] = [[main_eng[0],sec_eng[0]] , f\"{main_eng[1]}, {sec_eng[1]}\"]\n",
        "                i+=1\n",
        "        \n",
        "    def get_full_action(self,id):\n",
        "        return self.all_actions[id]\n",
        "\n",
        "    def get_action(self,id,add_noise=True):\n",
        "        if add_noise :\n",
        "            return [self.all_actions[id][0][0]+make_noise(), self.all_actions[id][0][1]+make_noise()]\n",
        "        else:\n",
        "            return self.all_actions[id][0]\n",
        "\n",
        "    def get_description(self,id):\n",
        "        return self.all_actions[id][1]\n",
        "    def get_action_count(self):\n",
        "        return len(self.all_actions)\n",
        "actions = defaultActions()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbb1iMa0X-Ol"
      },
      "source": [
        "class model(nn.Module):\n",
        "    def __init__(self, layers, name=\"\"):\n",
        "        super(model, self).__init__()\n",
        "        self.name = \"\"\n",
        "        self.layers = layers\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def name(self):\n",
        "        return self.name\n",
        "\n",
        "    def model_summery(self):\n",
        "        return self.features.summary()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld8W5xvqX-Ol"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DafsbPV3X-Ol"
      },
      "source": [
        "input_size = 8\n",
        "h1 = 16\n",
        "h2 = 16\n",
        "h3 = 16 \n",
        "h4 = 16\n",
        "h5 = 16\n",
        "output_size = actions.get_action_count()\n",
        "layers = [nn.Linear(input_size,h1) ,nn.ReLU(inplace=True), #, nn.BatchNorm1d(h1)\n",
        "         nn.Linear(h1,h2) ,nn.ReLU(inplace=True),\n",
        "#          nn.Linear(h2,h3) ,nn.ReLU(inplace=True),\n",
        "#          nn.Linear(h3,h4) , nn.ReLU(inplace=True),\n",
        "#          nn.Linear(h4,h5) ,nn.ReLU(inplace=True),\n",
        "         nn.Linear(h5,output_size),nn.ReLU(inplace=True) # , nn.BatchNorm1d(output_size)\n",
        "         ]\n",
        "for x in layers:\n",
        "    if isinstance(x, nn.Linear):\n",
        "        nn.init.normal_(x.weight, mean=0, std=1.0)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp4NQ6inX-Ol"
      },
      "source": [
        "\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCHLYkMkLzcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "3ad8135f-09e6-4861-90ea-273edf23458d"
      },
      "source": [
        "# Box2d Environment\n",
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "env.reset()\n",
        "plt.imshow(env.render('rgb_array'))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcb73788050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh4v_3zCRepL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b162eddd-e91d-4043-b3f7-bcf2a86bdadb"
      },
      "source": [
        "state_size = env.observation_space\n",
        "print(\"state size is:\", state_size)\n",
        "a = env.action_space\n",
        "print(\"action size=\",a) \n",
        "state = env.reset()\n",
        "print(state)   "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state size is: Box(-inf, inf, (8,), float32)\n",
            "action size= Box(-1.0, 1.0, (2,), float32)\n",
            "[ 0.0070425   1.4146249   0.7133082   0.16463538 -0.00815367 -0.161575\n",
            "  0.          0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTfAdl7dSS-K"
      },
      "source": [
        "# Action Space\n",
        "            #is two floats [main engine, left-right engines].\n",
        "            # Main engine: -1..0 off, 0..+1 throttle from 50% to 100% power. Engine can't work with less than 50% power.\n",
        "            # Left-right:  -1.0..-0.5 fire left engine, +0.5..+1.0 fire right engine, -0.5..0.5 off\n",
        "            self.action_space = spaces.Box(-1, +1, (2,), dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g_F9GGEX-On"
      },
      "source": [
        "DF = 0.9 #discount_factor\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 200\n",
        "max_iterations = 3000\n",
        "steps_done = 0\n",
        "TARGET_UPDATE = 10\n",
        "BATCH_SIZE = 50\n",
        "GAMMA = 0.999\n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "#mytestmodel.zero_grad()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeuwA3RqX-On",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7cb6954-f6eb-417f-a477-ba724cb1d284"
      },
      "source": [
        "policy_net =  model(layers).to(device)\n",
        "target_net =  model(layers).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model(\n",
              "  (features): Sequential(\n",
              "    (0): Linear(in_features=8, out_features=16, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): Linear(in_features=16, out_features=9, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOLFojNKX-On"
      },
      "source": [
        "optimizer = optim.SGD(policy_net.parameters(), lr=0.3 )#5e-6 RMSprop\n",
        "dtype = torch.float\n",
        "losses = []\n",
        "all_rewards = []\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQaFvJdvM4qX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43983b4a-a292-4e61-9ae9-fed4e59fa535"
      },
      "source": [
        "losses = []\n",
        "all_rewards = []\n",
        "memory = ReplayMemory(10000)\n",
        "for a in range(1000):\n",
        "    print(\"Episode: \",a,\"\\n\",\"-\"*50)\n",
        "    env = gym.make('LunarLanderContinuous-v2')\n",
        "    env.reset()\n",
        "    env = wrap_env(env)\n",
        "    done = False\n",
        "    iter = 0\n",
        "#     print(done)\n",
        "    observation = state = env.reset()\n",
        "\n",
        "    action = 1\n",
        "    TotalReward = 0\n",
        "    TotalLoss=0\n",
        "    df = DF\n",
        "\n",
        "    while not done and iter < max_iterations :\n",
        "      iter +=1\n",
        "      \n",
        "    #   action = env.action_space.sample()\n",
        "      if  True:\n",
        "\n",
        "          sample = random.random()\n",
        "          eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
        "          steps_done += 1\n",
        "          state_values = policy_net.forward(torch.from_numpy(observation))\n",
        "          if sample > eps_threshold:\n",
        "                # t.max(1) will return largest column value of each row.\n",
        "                # second column on max result is index of where max element was\n",
        "                # found, so we pick action with the larger expected reward.\n",
        "              real_action = state_values.argmax()\n",
        "\n",
        "          else:\n",
        "#               print(\"random sample\")\n",
        "              real_action = torch.tensor(random.randrange(actions.get_action_count()), device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "          action = actions.get_action(real_action.item())\n",
        "          observation, reward, done, _ = env.step(action)\n",
        "          with torch.no_grad():\n",
        "              next_values = target_net.forward(torch.from_numpy(observation))\n",
        "          if done and True:\n",
        "              new_reward = next_values.max()+0.1\n",
        "          else:\n",
        "            observation, new_reward, done, _ = env.step(action)\n",
        "    #       state_values[torch.isnan(state_values)] = 0\n",
        "    #       next_values[torch.isnan(next_values)] = 0\n",
        "          next_state = observation\n",
        "          next_val = next_values.max() if next_values.max()!=0 and next_values.max() is not None else -0.1\n",
        "\n",
        "          label = torch.tensor(reward + (df* new_reward), dtype=torch.float)\n",
        "          df *=df\n",
        "\n",
        "          print(iter,\"action is:\",actions.get_full_action(real_action.item()) ,\n",
        "                 \"reward: \",reward,\"full:\",label,\n",
        "                \"state_value:\",state_values,\n",
        "                \"max opt\",state_values.gather(-1,real_action))\n",
        "          memory.push(state, action, next_state, reward)\n",
        "          # continue\n",
        "          print(real_action.unsqueeze(0))\n",
        "          loss = F.smooth_l1_loss(state_values.gather(-1,real_action),label ) # Huber .unsqueeze(0)\n",
        "          optimizer.zero_grad()\n",
        "#           if loss != None:\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      else:\n",
        "          transitions = memory.sample(BATCH_SIZE)\n",
        "          batch = Transition(*zip(*transitions))\n",
        "          non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
        "          print(f\"iter {iter}\")\n",
        "          state_batch = batch.state\n",
        "          action_batch = batch.action\n",
        "          reward_batch = batch.reward\n",
        "          non_final_next_states = torch.tensor([s for s in batch.next_state if s is not None])\n",
        "          state_values =[]\n",
        "          with torch.no_grad():\n",
        "              for i in range(len(state_batch)):\n",
        "                  our_s = policy_net.forward(torch.from_numpy(state_batch[i])).tolist()\n",
        "                  state_values.append(our_s)\n",
        "          state_values = torch.as_tensor(state_values)\n",
        "          motor_controls = state_values.clone().detach().numpy()\n",
        "    #       state_values[torch.isnan(state_values)] = 0\n",
        "    #       next_values[torch.isnan(next_values)] = 0\n",
        "          next_val = next_values.max() if next_values.max()!=0 and next_values.max() is not None else -0.1\n",
        "          # state_values = torch.cat(state_values)\n",
        "          # observation, reward, done, _ = env.step(action_batch[0])\n",
        "          # state_values = policy_net.forward(torch.from_numpy(observation))\n",
        "          # print(\"action is:\",actions.get_full_action(state_values.argmax().item())[0] ,\"reward: \",reward)\n",
        "          # next_values = target_net.forward(torch.from_numpy(observation))\n",
        "          real_action = []\n",
        "          for i in range(len(state_values)):\n",
        "             real_action.append(actions.get_full_action(state_values[i].argmax().item())[0])\n",
        "          real_action = torch.as_tensor(real_action)\n",
        "          next_state_values = torch.zeros(BATCH_SIZE, device=device).float()\n",
        "          next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "          expected_state_action_values = (next_state_values * GAMMA) + torch.tensor(reward_batch)\n",
        "          expected_state_action_values = expected_state_action_values.float()\n",
        "          print(f\"hedva { expected_state_action_values.unsqueeze(1)}\")\n",
        "          # print(f\"yosi  {state_values.gather(-1,real_action)}\")\n",
        "          loss = F.smooth_l1_loss(state_values, expected_state_action_values.unsqueeze(1).double()).float()\n",
        "          TotalLoss += loss.data.item()\n",
        "          TotalReward+= sum(reward_batch)\n",
        "          # Optimize the model\n",
        "          optimizer.zero_grad()\n",
        "          print(f\"loss {loss}\")\n",
        "          print(f\"loss.data {loss.data}\")\n",
        "          loss.requres_grad = True\n",
        "          loss.backward()\n",
        "          for param in policy_net.parameters():\n",
        "              param.grad.data.clamp_(-1, 1)\n",
        "          optimizer.step()\n",
        "          # if done and True:\n",
        "          #     new_reward = next_values.max()+0.1\n",
        "          # else:\n",
        "          #     observation, new_reward, done, _ = env.step(action)\n",
        "          # label = torch.tensor(reward + (df* new_reward), dtype=torch.float)\n",
        "      # loss = F.smooth_l1_loss(state_values[real_action],label ) # Huber .unsqueeze(0)\n",
        "\n",
        "          print (loss.data)\n",
        "      TotalLoss += loss.data.item()\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "      TotalReward+= reward\n",
        "      print(\"state is:\", observation)\n",
        "\n",
        "      #if you want to see results on real-time 'open' the following 4 lines\n",
        "      if iter % TARGET_UPDATE/2 == 0:\n",
        "          screen = env.render(mode='rgb_array')\n",
        "          plt.imshow(screen)\n",
        "          ipythondisplay.clear_output(wait=True)\n",
        "          ipythondisplay.display(plt.gcf())\n",
        "\n",
        "\n",
        "      if iter % TARGET_UPDATE == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "            \n",
        "    print(TotalReward,iter,done)\n",
        "    all_rewards.append(TotalReward)\n",
        "    losses.append(TotalLoss/iter)\n",
        "    print(\"-\"*50)\n",
        "    if  a % TARGET_UPDATE*5 == 0:\n",
        "        ipythondisplay.clear_output(wait=True)\n",
        "        pickle.dump(policy_net, open(f\"model.pkl\", \"wb\"))\n",
        "        plot(a, all_rewards, losses)\n",
        "print(f\"all {all_rewards}\")\n",
        "print(f\"len {len(all_rewards)}\")\n",
        "avg = sum(all_rewards) / len(all_rewards)\n",
        "print(f\"avg = {avg}\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "11 action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8239030345516767 full: tensor(-0.8239) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([0])\n",
            "state is: [ 0.18241644  1.5124488   0.84112346  0.07383822 -0.14849696 -0.17196883\n",
            "  0.          0.        ]\n",
            "12 action is: [[1, 0], 'Main strong, Left Right off'] reward:  -1.0568618411405963 full: tensor(-1.0569) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([6])\n",
            "state is: [ 0.19917555  1.5156429   0.8561648   0.06844845 -0.16595566 -0.16816236\n",
            "  0.          0.        ]\n",
            "13 action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.576167566459117 full: tensor(-2.5762) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([0])\n",
            "state is: [ 0.21640234  1.5189981   0.8710003   0.07380605 -0.18295589 -0.16840509\n",
            "  0.          0.        ]\n",
            "14 action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8884447903776049 full: tensor(-0.8884) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([0])\n",
            "state is: [ 0.2336547   1.5205677   0.87099713  0.02046097 -0.1997963  -0.16840363\n",
            "  0.          0.        ]\n",
            "15 action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9421591786615977 full: tensor(-0.9422) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([0])\n",
            "state is: [ 0.2509075   1.5197409   0.8709935  -0.03288406 -0.21663652 -0.16840217\n",
            "  0.          0.        ]\n",
            "16 action is: [[0.5, 1], 'Main slow, Right strong'] reward:  -2.9341971272765295 full: tensor(-2.9342) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([5])\n",
            "state is: [ 2.6861334e-01  1.5194426e+00  9.0673560e-01  6.6310298e-05\n",
            " -2.3969641e-01 -2.5113896e-01  0.0000000e+00  0.0000000e+00]\n",
            "17 action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.398126859428146 full: tensor(-1.3981) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([0])\n",
            "state is: [ 0.2865015   1.5177397   0.90672606 -0.05329282 -0.2648099  -0.25113344\n",
            "  0.          0.        ]\n",
            "18 action is: [[0, 0], 'Main off, Left Right off'] reward:  -3.4648777864815656 full: tensor(-3.4649) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([0])\n",
            "state is: [ 0.304879    1.5152749   0.9341963  -0.06424376 -0.28907287 -0.24178341\n",
            "  0.          0.        ]\n",
            "19 action is: [[1, 0], 'Main strong, Left Right off'] reward:  -3.303063598901235 full: tensor(-3.3031) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([6])\n",
            "state is: [ 0.3239789   1.5146176   0.9817802  -0.00209414 -0.31387174 -0.24652612\n",
            "  0.          0.        ]\n",
            "20 action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.20693913408162 full: tensor(-2.2069) state_value: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<ReluBackward1>) max opt tensor(0., grad_fn=<GatherBackward>)\n",
            "tensor([0])\n",
            "state is: [ 0.3436493   1.5143421   1.0032036  -0.01118448 -0.33877817 -0.2470711\n",
            "  0.          0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzyI3vKZQiR6"
      },
      "source": [
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_ve2aViqJa"
      },
      "source": [
        "print(iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQSL6GAC3Dw3"
      },
      "source": [
        "#Draw random samples from a normal (Gaussian) distribution.\n",
        "mu, sigma = 0, 0.05 # mean and standard deviation\n",
        "s = np.random.normal(mu, sigma, 1)\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2N8kYsjX-Ow"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RngQ0ZUX-Ox"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScmN3t6LX-Ox"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}