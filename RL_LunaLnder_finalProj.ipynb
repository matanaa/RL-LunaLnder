{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HND9HYhOE89T"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-cVn8qQKtJq"
   },
   "source": [
    "Based on the following links to create this notebook:\n",
    "\n",
    "https://colab.research.google.com/drive/18LdlDDT87eb8cCTHZsXyS9ksQPzL3i6H\n",
    "\n",
    "https://colab.research.google.com/drive/1tug_bpg8RwrFOI8C6Ed-zo0OgD3yfnWy#scrollTo=bhsj7BTPHepg\n",
    "\n",
    "https://colab.research.google.com/drive/1tug_bpg8RwrFOI8C6Ed-zo0OgD3yfnWy\n",
    "\n",
    "\n",
    "To run Gym, you have to install prerequisites like xvbf,opengl & other python-dev packages using the following codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmtbAjPPKiFw",
    "outputId": "9d745500-a623-46dc-9717-57fd01f29646"
   },
   "outputs": [],
   "source": [
    "!pip install gym  torch\n",
    "!apt-get install python-opengl ffmpeg -y \n",
    "!apt install xvfb -y \n",
    "!pip install pyvirtualdisplay  \n",
    "!pip install piglet \n",
    "!pip install gym[box2d] \n",
    "!pip install tensorflow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_hxdz4ALVQ3"
   },
   "outputs": [],
   "source": [
    "# This code creates a virtual display to draw game images on. \n",
    "# If you are running locally, just ignore it\n",
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1GqN0iRLaZk"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "gymlogger.set_level(40) # error only\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "from collections import namedtuple\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILbriB_oLn5T"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment and displaying it\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "\n",
    "def show_video():\n",
    "  mp4list = glob.glob('video/*.mp4')\n",
    "  if len(mp4list) > 0:\n",
    "    mp4 = mp4list[0]\n",
    "    video = io.open(mp4, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "  else: \n",
    "    print(\"Could not find video\")\n",
    "    \n",
    "\n",
    "def wrap_env(env):\n",
    "  env = Monitor(env, './video', force=True)\n",
    "  return env\n",
    "\n",
    "def make_noise():\n",
    "    mu, sigma = 0, 0.05 # mean and standard deviation\n",
    "    return np.random.normal(mu, sigma, 1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class defaultActions:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.main = [[0 , \"Main off\"],\n",
    "                     [0.5 ,\"Main slow\"],\n",
    "                     [0.75 , \"Main meduim\"],\n",
    "                     [1    , \"Main strong\"]\n",
    "                    ]\n",
    "        self.left_right = [\n",
    "                        [0, \"Left Right off\"],\n",
    "                        [-0.5 , \"Left slow\"],\n",
    "                        [-0.75  , \"Left meduim\"],\n",
    "                        [-1 , \"Left strong\"],\n",
    "                        \n",
    "                        [0.5 , \"Right slow\"],\n",
    "                        [0.75  , \"Right meduim\"],\n",
    "                        [1 , \"Right strong\"],\n",
    "                        ]\n",
    "        self.all_actions = {}\n",
    "        i = 0  \n",
    "        for main_eng in self.main:\n",
    "            for sec_eng in self.left_right:\n",
    "#                 print (f\"a{i},act:[{main_eng[0]},{sec_eng[0]},{main_eng[1]} {sec_eng[1]}]\")\n",
    "                self.all_actions[i] = [[main_eng[0],sec_eng[0]] , f\"{main_eng[1]}, {sec_eng[1]}\"]\n",
    "                i+=1\n",
    "        \n",
    "    def get_full_action(self,id):\n",
    "        return self.all_actions[id]\n",
    "\n",
    "    def get_action(self,id,add_noise=True):\n",
    "        if add_noise :\n",
    "            return [self.all_actions[id][0][0]+make_noise(), self.all_actions[id][0][1]+make_noise()]\n",
    "        else:\n",
    "            return self.all_actions[id][0]\n",
    "\n",
    "    def get_description(self,id):\n",
    "        return self.all_actions[id][1]\n",
    "    def get_action_count(self):\n",
    "        return len(self.all_actions)\n",
    "actions = defaultActions()\n",
    "actions.get_full_action(21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, layers, name=\"\"):\n",
    "        super(model, self).__init__()\n",
    "        self.name = \"\"\n",
    "        self.layers = layers\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def name(self):\n",
    "        return self.name\n",
    "\n",
    "    def model_summery(self):\n",
    "        return self.features.summary()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 8\n",
    "h1 = 500\n",
    "h2 = 500\n",
    "h3 = 500 \n",
    "h4 = 500\n",
    "h5 = 500\n",
    "output_size = actions.get_action_count()\n",
    "layers = [nn.Linear(input_size,h1) ,nn.ReLU(inplace=True), #, nn.BatchNorm1d(h1)\n",
    "         nn.Linear(h1,h2) ,nn.ReLU(inplace=True),\n",
    "#          nn.Linear(h2,h3) ,nn.ReLU(inplace=True),\n",
    "#          nn.Linear(h3,h4) , nn.ReLU(inplace=True),\n",
    "#          nn.Linear(h4,h5) ,nn.ReLU(inplace=True),\n",
    "         nn.Linear(h5,output_size),nn.ReLU(inplace=True) # , nn.BatchNorm1d(output_size)\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "yCHLYkMkLzcf",
    "outputId": "a6a0fa34-ac87-47ca-9437-68de50367627"
   },
   "outputs": [],
   "source": [
    "# Box2d Environment\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "env.reset()\n",
    "plt.imshow(env.render('rgb_array'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wh4v_3zCRepL",
    "outputId": "9050bd8f-a7ba-488a-e09d-b340f97e99ee"
   },
   "outputs": [],
   "source": [
    "state_size = env.observation_space\n",
    "print(\"state size is:\", state_size)\n",
    "a = env.action_space\n",
    "print(\"action size=\",a) \n",
    "state = env.reset()\n",
    "print(state)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTfAdl7dSS-K"
   },
   "source": [
    "# Action Space\n",
    "            #is two floats [main engine, left-right engines].\n",
    "            # Main engine: -1..0 off, 0..+1 throttle from 50% to 100% power. Engine can't work with less than 50% power.\n",
    "            # Left-right:  -1.0..-0.5 fire left engine, +0.5..+1.0 fire right engine, -0.5..0.5 off\n",
    "            self.action_space = spaces.Box(-1, +1, (2,), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 0.9 #discount_factor\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "max_iterations = 3000\n",
    "steps_done = 0\n",
    "TARGET_UPDATE = 10\n",
    "BATCH_SIZE =20\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "#mytestmodel.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net =  model(layers).to(device)\n",
    "target_net =  model(layers).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = optim.RMSprop(policy_net.parameters(), lr=5e-6, )\n",
    "dtype = torch.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQaFvJdvM4qX",
    "outputId": "abb1bb94-322c-4052-ea47-3924aa01d167"
   },
   "outputs": [],
   "source": [
    "\n",
    "for a in range(100):\n",
    "    memory = ReplayMemory(10000)\n",
    "    print(\"Episode: \",a,\"\\n\",\"-\"*50)\n",
    "    env = gym.make('LunarLanderContinuous-v2')\n",
    "    env.reset()\n",
    "    env = wrap_env(env)\n",
    "    done = False\n",
    "    iter = 0\n",
    "#     print(done)\n",
    "    observation = state = env.reset()\n",
    "\n",
    "    action = 1\n",
    "    TotalReward = 0\n",
    "\n",
    "    while not done and iter < max_iterations :\n",
    "      iter +=1\n",
    "      \n",
    "    #   action = env.action_space.sample()\n",
    "      if len(memory) < BATCH_SIZE:\n",
    "\n",
    "          sample = random.random()\n",
    "          eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "          steps_done += 1\n",
    "          state_values = policy_net.forward(torch.from_numpy(observation))\n",
    "          if sample > eps_threshold:\n",
    "                # t.max(1) will return largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "              real_action = state_values.argmax()\n",
    "\n",
    "          else:\n",
    "#               print(\"random sample\")\n",
    "              real_action = torch.tensor(random.randrange(actions.get_action_count()), device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "          action = actions.get_action(real_action.item())\n",
    "          observation, reward, done, _ = env.step(action)\n",
    "\n",
    "          next_values = target_net.forward(torch.from_numpy(observation))\n",
    "          if done :\n",
    "                break\n",
    "          observation, new_reward, done, _ = env.step(action)\n",
    "    #       state_values[torch.isnan(state_values)] = 0\n",
    "    #       next_values[torch.isnan(next_values)] = 0\n",
    "          next_val = next_values.max() if next_values.max()!=0 and next_values.max() is not None else -0.1\n",
    "\n",
    "          label = torch.tensor(reward + (df* new_reward), dtype=torch.float)\n",
    "\n",
    "          print(iter,\"action is:\",actions.get_full_action(real_action.item()) ,\n",
    "                 \"reward: \",reward,\"full:\",label,\n",
    "                \"state_value:\",state_values,\n",
    "                \"max opt\",state_values.gather(-1,real_action))\n",
    "#           print(real_action.unsqueeze(0))\n",
    "          loss = F.smooth_l1_loss(state_values.gather(-1,real_action),label ) # Huber .unsqueeze(0)\n",
    "    #       print (loss)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          if loss != None:\n",
    "              loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "\n",
    "          TotalReward+= reward\n",
    "      #print(\"state is:\", observation)\n",
    "\n",
    "      #if you want to see results on real-time 'open' the following 4 lines\n",
    "#       if iter % TARGET_UPDATE == 0:\n",
    "#           screen = env.render(mode='rgb_array')\n",
    "#           plt.imshow(screen)\n",
    "#           ipythondisplay.clear_output(wait=True)\n",
    "#           ipythondisplay.display(plt.gcf())\n",
    "\n",
    "\n",
    "      if iter % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "    print(TotalReward,iter,done)\n",
    "    print(\"Episode: \",a,\"\\n\",\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "BzyI3vKZQiR6",
    "outputId": "dbe0e96e-3efc-42ed-f81b-a96ff5870be6"
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rY_ve2aViqJa",
    "outputId": "a1b0ce01-0ea3-4237-9bc1-15d741cb4377"
   },
   "outputs": [],
   "source": [
    "print(iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQSL6GAC3Dw3",
    "outputId": "ad6dbb03-26be-4c36-fc22-7f714419c493"
   },
   "outputs": [],
   "source": [
    "#Draw random samples from a normal (Gaussian) distribution.\n",
    "mu, sigma = 0, 0.05 # mean and standard deviation\n",
    "s = np.random.normal(mu, sigma, 1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "RL-LunaLnder-finalProj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
