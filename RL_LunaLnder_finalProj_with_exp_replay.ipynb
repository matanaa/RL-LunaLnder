{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL-LunaLnder-finalProj.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HND9HYhOE89T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-cVn8qQKtJq"
      },
      "source": [
        "Based on the following links to create this notebook:\n",
        "\n",
        "https://colab.research.google.com/drive/18LdlDDT87eb8cCTHZsXyS9ksQPzL3i6H\n",
        "\n",
        "https://colab.research.google.com/drive/1tug_bpg8RwrFOI8C6Ed-zo0OgD3yfnWy#scrollTo=bhsj7BTPHepg\n",
        "\n",
        "https://colab.research.google.com/drive/1tug_bpg8RwrFOI8C6Ed-zo0OgD3yfnWy\n",
        "\n",
        "\n",
        "To run Gym, you have to install prerequisites like xvbf,opengl & other python-dev packages using the following codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2dc68sUdVH8"
      },
      "source": [
        "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmtbAjPPKiFw",
        "outputId": "a742898a-704f-47e5-eca0-04863383777a"
      },
      "source": [
        "!pip install gym  torch\n",
        "!apt-get install python-opengl ffmpeg -y \n",
        "!apt install xvfb -y \n",
        "!pip install pyvirtualdisplay  \n",
        "!pip install piglet \n",
        "!pip install gym[box2d] \n",
        "!pip install tensorflow \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 11 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.0)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: piglet in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: piglet-templates in /usr/local/lib/python3.7/dist-packages (from piglet) (1.1.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.1.1)\n",
            "Requirement already satisfied: Parsley in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.3)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (1.6.3)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from piglet-templates->piglet) (20.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (0.36.2)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from astunparse->piglet-templates->piglet) (1.15.0)\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.4.1)\n",
            "Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (2.3.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]) (0.16.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (53.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzek7gjVdVH9",
        "outputId": "b6e67635-dcca-4f41-8fea-751fe114c092",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f1210dffb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_hxdz4ALVQ3"
      },
      "source": [
        "# This code creates a virtual display to draw game images on. \n",
        "# If you are running locally, just ignore it\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
        "    !bash ../xvfb start\n",
        "    %env DISPLAY=:1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1GqN0iRLaZk"
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) # error only\n",
        "# import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "from collections import namedtuple\n",
        "from itertools import count\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILbriB_oLn5T"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env\n",
        "\n",
        "def make_noise():\n",
        "    mu, sigma = 0, 0.05 # mean and standard deviation\n",
        "    return np.random.normal(mu, sigma, 1)[0]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xedj9GNHdVH_"
      },
      "source": [
        "# My Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr6hSEWqdVH_"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UONfKGSsdVH_",
        "outputId": "e886e8d4-b450-434d-ce99-4d7c10eca6b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class defaultActions:\n",
        "    def __init__(self):\n",
        "\n",
        "        self.main = [[0 , \"Main off\"],\n",
        "                     [0.5 ,\"Main slow\"],\n",
        "                     [0.75 , \"Main meduim\"],\n",
        "                     [1    , \"Main strong\"]\n",
        "                    ]\n",
        "        self.left_right = [\n",
        "                        [0, \"Left Right off\"],\n",
        "                        [-0.5 , \"Left slow\"],\n",
        "                        [-0.75  , \"Left meduim\"],\n",
        "                        [-1 , \"Left strong\"],\n",
        "                        \n",
        "                        [0.5 , \"Right slow\"],\n",
        "                        [0.75  , \"Right meduim\"],\n",
        "                        [1 , \"Right strong\"],\n",
        "                        ]\n",
        "        self.all_actions = {}\n",
        "        i = 0  \n",
        "        for main_eng in self.main:\n",
        "            for sec_eng in self.left_right:\n",
        "#                 print (f\"a{i},act:[{main_eng[0]},{sec_eng[0]},{main_eng[1]} {sec_eng[1]}]\")\n",
        "                self.all_actions[i] = [[main_eng[0],sec_eng[0]] , f\"{main_eng[1]}, {sec_eng[1]}\"]\n",
        "                i+=1\n",
        "        \n",
        "    def get_full_action(self,id):\n",
        "        return self.all_actions[id]\n",
        "\n",
        "    def get_action(self,id,add_noise=True):\n",
        "        if add_noise :\n",
        "            return [self.all_actions[id][0][0]+make_noise(), self.all_actions[id][0][1]+make_noise()]\n",
        "        else:\n",
        "            return self.all_actions[id][0]\n",
        "\n",
        "    def get_description(self,id):\n",
        "        return self.all_actions[id][1]\n",
        "    def get_action_count(self):\n",
        "        return len(self.all_actions)\n",
        "actions = defaultActions()\n",
        "actions.get_action_count()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj3MtWt6dVIA"
      },
      "source": [
        "class model(nn.Module):\n",
        "    def __init__(self, layers, name=\"\"):\n",
        "        super(model, self).__init__()\n",
        "        self.name = \"\"\n",
        "        self.layers = layers\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def name(self):\n",
        "        return self.name\n",
        "\n",
        "    def model_summery(self):\n",
        "        return self.features.summary()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl8QJR9GXX3Y"
      },
      "source": [
        "Transition = namedtuple('Transition',\r\n",
        "                        ('state', 'action', 'next_state', 'reward'))\r\n",
        "\r\n",
        "\r\n",
        "class ReplayMemory(object):\r\n",
        "\r\n",
        "    def __init__(self, capacity):\r\n",
        "        self.capacity = capacity\r\n",
        "        self.memory = []\r\n",
        "        self.position = 0\r\n",
        "\r\n",
        "    def push(self, *args):\r\n",
        "        \"\"\"Saves a transition.\"\"\"\r\n",
        "        if len(self.memory) < self.capacity:\r\n",
        "            self.memory.append(None)\r\n",
        "        self.memory[self.position] = Transition(*args)\r\n",
        "        self.position = (self.position + 1) % self.capacity\r\n",
        "\r\n",
        "    def sample(self, batch_size):\r\n",
        "        return random.sample(self.memory, batch_size)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.memory)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyO5Si1IdVIA"
      },
      "source": [
        "TARGET_UPDATE = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696-pnAhdVIA"
      },
      "source": [
        "input_size = 8\n",
        "h1 = 500\n",
        "h2 = 500 \n",
        "h3 = 500 \n",
        "h4 = 500\n",
        "h5 = 500\n",
        "output_size = actions.get_action_count()\n",
        "layers = [nn.Linear(input_size,h1) ,nn.ReLU(inplace=True), #, nn.BatchNorm1d(h1)\n",
        "         nn.Linear(h1,h2) ,nn.ReLU(inplace=True),\n",
        "         nn.Linear(h2,h3) ,nn.ReLU(inplace=True),\n",
        "         nn.Linear(h3,h4) , nn.ReLU(inplace=True),\n",
        "         nn.Linear(h4,h5) ,nn.ReLU(inplace=True),\n",
        "         nn.Linear(h5,output_size),nn.ReLU(inplace=True) # , nn.BatchNorm1d(output_size)\n",
        "         ]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "yCHLYkMkLzcf",
        "outputId": "308447c6-5e37-40ef-df17-3c59bc769164"
      },
      "source": [
        "# Box2d Environment\n",
        "env = gym.make('LunarLanderContinuous-v2')\n",
        "env.reset()\n",
        "plt.imshow(env.render('rgb_array'))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f11ac2e8210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh4v_3zCRepL",
        "outputId": "5e89bf6f-fd49-4fe4-b07c-a479a1170d65"
      },
      "source": [
        "state_size = env.observation_space\n",
        "print(\"state size is:\", state_size)\n",
        "a = env.action_space\n",
        "print(\"action size=\",a) \n",
        "state = env.reset()\n",
        "print(state)   "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state size is: Box(-inf, inf, (8,), float32)\n",
            "action size= Box(-1.0, 1.0, (2,), float32)\n",
            "[-1.3311387e-03  1.4140332e+00 -1.3484649e-01  1.3835415e-01\n",
            "  1.5492757e-03  3.0544778e-02  0.0000000e+00  0.0000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTfAdl7dSS-K"
      },
      "source": [
        "# Action Space\n",
        "            #is two floats [main engine, left-right engines].\n",
        "            # Main engine: -1..0 off, 0..+1 throttle from 50% to 100% power. Engine can't work with less than 50% power.\n",
        "            # Left-right:  -1.0..-0.5 fire left engine, +0.5..+1.0 fire right engine, -0.5..0.5 off\n",
        "            self.action_space = spaces.Box(-1, +1, (2,), dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERvRtjVEdVIB",
        "outputId": "dad0b8a1-c66a-43aa-f1d0-d6a4e78d7ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = 0.9 #discount_factor\n",
        "not_val = -999999\n",
        "last_val = not_val\n",
        "last_out = None\n",
        "max_iterations = 3000\n",
        "BATCH_SIZE = 128\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "#mytestmodel.zero_grad()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f11ac217a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSYreQ9bdVIC"
      },
      "source": [
        "policy_net =  model(layers).to(device)\n",
        "target_net =  model(layers).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "optimizer = optim.SGD(policy_net.parameters(), lr=0.35, momentum=0.9)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQaFvJdvM4qX",
        "outputId": "6a957947-dbab-4873-a213-3198a8c08b88"
      },
      "source": [
        "for a in range(5):\n",
        "    memory = ReplayMemory(10000)\n",
        "    env = gym.make('LunarLanderContinuous-v2')\n",
        "    env.reset()\n",
        "    env = wrap_env(env)\n",
        "    done = False\n",
        "    iter = 0\n",
        "    print(done)\n",
        "    observation = state = env.reset()\n",
        "\n",
        "    action = 1\n",
        "    TotalReward = 0\n",
        "\n",
        "    while not done and iter < max_iterations :\n",
        "      iter +=1\n",
        "      optimizer.zero_grad()\n",
        "    #   action = env.action_space.sample()\n",
        "      action =  random.choice(actions.all_actions)\n",
        "      if len(memory) < BATCH_SIZE:\n",
        "        state_values = policy_net.forward(torch.from_numpy(observation))\n",
        "        action = actions.get_action(state_values.argmax().item())\n",
        "        observation, reward, done, _ = env.step(action)\n",
        "        next_state = observation\n",
        "        print(\"action is:\",actions.get_full_action(state_values.argmax().item()) ,\"reward: \",reward)\n",
        "        next_values = target_net.forward(torch.from_numpy(observation))\n",
        "        memory.push(state, action, next_state, reward)\n",
        "      else:\n",
        "        print(f\"iter {iter}\")\n",
        "        transitions = memory.sample(BATCH_SIZE)\n",
        "        batch = Transition(*zip(*transitions))\n",
        "        print(f\"yalla {batch.state}\")\n",
        "        print(f\"yalla2 {batch.action}\")\n",
        "        state_batch = torch.cat(batch.state)\n",
        "        action_batch = torch.cat(batch.action)\n",
        "        reward_batch = torch.cat(batch.reward)\n",
        "        # state_values = policy_net(state_batch).gather(1, action_batch)\n",
        "        observation, reward, done, _ = env.step(action_batch[0])\n",
        "        state_values = policy_net.forward(torch.from_numpy(observation))\n",
        "        print(\"action is:\",actions.get_full_action(state_values.argmax().item()) ,\"reward: \",reward)\n",
        "        next_values = target_net.forward(torch.from_numpy(observation))\n",
        "\n",
        "      # action = actions.get_action(state_values.argmax().item())\n",
        "      # observation, reward, done, _ = env.step(action)\n",
        "      # print(\"action is:\",actions.get_full_action(state_values.argmax().item()) ,\"reward: \",reward)\n",
        "      # next_values = target_net.forward(torch.from_numpy(observation))\n",
        "      # memory.push(state, action, observation, reward)\n",
        "\n",
        "      loss = F.smooth_l1_loss(state_values,torch.tensor([reward +df*next_values.max().item()], dtype=torch.float).unsqueeze(0) ) # Huber .unsqueeze(0)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      TotalReward+= reward\n",
        "      #print(\"state is:\", observation)\n",
        "\n",
        "      #if you want to see results on real-time 'open' the following 4 lines\n",
        "    #   screen = env.render(mode='rgb_array')\n",
        "    #   plt.imshow(screen)\n",
        "    #   ipythondisplay.clear_output(wait=True)\n",
        "    #   ipythondisplay.display(plt.gcf())\n",
        "\n",
        "\n",
        "      if iter % TARGET_UPDATE == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "    print(TotalReward,iter)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  4.106969886156618\n",
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  2.9907442664915096\n",
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  2.5328481449116613\n",
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  1.826527344656538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  1.4868487406092992\n",
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  1.275782269973805\n",
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  -0.18965857397970923\n",
            "action is: [[1, 1], 'Main strong, Right strong'] reward:  -1.8695400855390734\n",
            "action is: [[0.5, -0.5], 'Main slow, Left slow'] reward:  0.23313115895777287\n",
            "action is: [[0.5, -0.5], 'Main slow, Left slow'] reward:  -1.3259143238549427\n",
            "action is: [[0.5, -0.5], 'Main slow, Left slow'] reward:  0.7028219886657655\n",
            "action is: [[0, 0.5], 'Main off, Right slow'] reward:  -3.049613954171008\n",
            "action is: [[0, 0.5], 'Main off, Right slow'] reward:  -3.400579932906993\n",
            "action is: [[0, 0.5], 'Main off, Right slow'] reward:  -3.091335658131186\n",
            "action is: [[0.5, -1], 'Main slow, Left strong'] reward:  -1.1121348653141\n",
            "action is: [[0.5, -1], 'Main slow, Left strong'] reward:  0.1455535265169499\n",
            "action is: [[0.5, -1], 'Main slow, Left strong'] reward:  -0.03764581453183835\n",
            "action is: [[0.5, -1], 'Main slow, Left strong'] reward:  -0.7201901793954164\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  2.3600955969025335\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  1.777927819205048\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  1.217079354897703\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -0.14314293866458228\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -1.761361546593622\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -1.457112935150966\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  0.21306663270821785\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -0.21376578700004528\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -0.016167308241210765\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -1.8569386682654283\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -2.0060519223907693\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -1.6921753224171971\n",
            "action is: [[1, -0.5], 'Main strong, Left slow'] reward:  -1.6455832606878562\n",
            "action is: [[0.5, -1], 'Main slow, Left strong'] reward:  1.0862026029062075\n",
            "action is: [[0, 0.75], 'Main off, Right meduim'] reward:  -0.7214610753182421\n",
            "action is: [[0, 0.75], 'Main off, Right meduim'] reward:  -1.2126677656485003\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7232576863751603\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.28648569326554707\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.35211830679190825\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3059860159780157\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.33424370959977523\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9955439464560414\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.3396515447676052\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5930137313754699\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.40666408646356444\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4494714537053994\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.08969092552266034\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.11943666743031828\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1325984770015396\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.19844501064952738\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7125192212246987\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4039511519333132\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.23538311688676572\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.687357268763708\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4444541467190959\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7763135360070919\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8100388530418627\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.06537268775805957\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.39419960166586065\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.41155067200458006\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.21246592173722548\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4086587126000154\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4206414007147714\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.394068864180241\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4411747706164135\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.44774526558936145\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.45180883568639274\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.3405354815197882\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.42666582254844343\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.0986662598637281\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4168022069399058\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4149220888410241\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.04230263385487659\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.37794554213297715\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.03107170973858045\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.9810759599111407\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.09588778861910327\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.3315003583539862\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.42133822733160287\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.8029664599525347\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.3136269275227335\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.5445794468507756\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5363046162383966\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5415421612630382\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.3770387383479488\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.5937025486854111\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.6222390883385174\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.7644643099736527\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.21327392994088543\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7401231533121972\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.0213422306723146\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.814086699121134\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8420607317116833\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.8978793518197961\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9406187072016792\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.170766712729801\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.0652119792470045\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.6110393745326291\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.236311111283868\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2965050801240352\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.538939692806349\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.005044580848237945\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.9371843324295526\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6625722424480784\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4722179697070146\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8216069159461483\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.92319732544874\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.032131682764799\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  9.520276697774886\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  6.139307501777495\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -100\n",
            "-107.08806640133855 109\n",
            "False\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5992901011122171\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.07832098781591412\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.07572429221670518\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4679735295574687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.071790256793315\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0535034589609835\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.10214474820810437\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.5037704818867725\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.12332873727422111\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.542965263921974\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.1582528696712302\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5184693675062817\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.19125315877738558\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.21918150041597073\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.6972063160745734\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7202957807096994\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.335219297529477\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.376970285385255\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4230094559757447\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.636205911841705\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0989543983709211\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.988481709079332\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.543573742172839\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.239277957035699\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5956940288268981\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.656379594346248\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.378967388795888\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.3027537328477363\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9879616895304991\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.3300540155950955\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7648869727695455\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8191920556716923\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.9329024651592988\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8940988425875105\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9485667807327616\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.727111070724567\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9801938998069772\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0313353040186257\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.5230771888877372\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.2709689582726016\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4255485930583973\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.288922899304623\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0833565817662816\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1243785309095529\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.163541372420923\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2005179722622188\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.3871780434185212\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.146214994763386\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.703011998197758\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1639671861169063\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.190805821692436\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2152742205415734\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2372697418118719\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2567528082907984\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2736932689670084\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.639516898704585\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7348902542302995\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.765834873649942\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2885432461172854\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.409688254587388\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.2130021304857905\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2270435227869712\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.838973848293256\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1748118227905024\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1800346883518955\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1673098614698916\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4497687224689457\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2279864731698353\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.229817018993458\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2303667867515742\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2298335463274839\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8943874624106343\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2157328850585714\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2657848891644448\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.323206682044315\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2056636584051716\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2047937537247435\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.203638384730425\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2023325627893087\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0892565044520666\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4596697813570927\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.292668252415865\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.9884671692581493\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2880450608622596\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6895413843088363\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.5828643806098284\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.066661977546653\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7672598478545183\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.366632530847653\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8165204490673772\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.3872476192015597\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.944161953339392\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7739722472840298\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -3.049384788300074\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4582001990500544\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4876773568924477\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.0298940447251654\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.59337133625246\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -3.3370422214062954\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.3819198738885006\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7102070562551717\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -3.228938682926048\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.808677657815167\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8682025433663512\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.93217566372914\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.0007831962381033\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.074250783498428\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.958405947777851\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.901105992640498\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.3416098808435777\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.434446633455991\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -3.6741776272520497\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -4.1345582830635745\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -4.500158940631127\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.848941599532168\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -100\n",
            "-285.55980332584204 116\n",
            "False\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.189542395298787\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.3451304862821303\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.338396138387054\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.304274596930071\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.259062845982669\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.4715047682573583\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7409066907419174\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7184783927742387\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.0580720485353083\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.007324566114562\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.0029788284245456\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.966708317455209\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9655901515857351\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.5026874416036151\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.955585153206954\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.13264493301608127\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8986209683123718\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.841719261866615\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.6384047984343113\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.42596005785055124\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7700704893284183\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7116848266709042\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.4962585178916925\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.16468540629911105\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.016492131037495\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6701406228161773\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6115266539258357\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.11176362937809473\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.2675776476554119\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5191398335453528\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.460145943837631\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.401018247701245\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.1926132427576932\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3483538410063147\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2890534452745896\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.09746791805316662\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.022762433960156148\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.6745622317349046\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.0824889960529789\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1206244199079833\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.1666566317283866\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.6673285149824665\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.7914820608636376\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.8681374122448858\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.16279282850477444\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0756914681167302\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.2929101127644458\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9893140240373555\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.44138614168115853\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9262725542547514\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.1006328722547551\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8239883627524307\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.906629029586145\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8069930859858516\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.9944073659212904\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7182761043557662\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.6586433422523328\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.599051174640266\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.2214218657521372\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.357847030632513\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.49612374247141133\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.43659777964879254\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.3770763376021762\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.9334624499557322\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.58082031557081\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.1370282858936323\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.799674246168189\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.576656042377101\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.323001653405413\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.26403387996549554\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.20520810692642044\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.6190520862220126\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.301329988771397\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.13051312535023385\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.07325708415561394\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.1935320347207266\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.039186230288351\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.09250023474081104\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.14251306432407773\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.1866733016768478\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.21934772502547162\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.22627078833986047\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.3149939721210044\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.22045926285184692\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  10.109107560966914\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  11.470187802595177\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -100\n",
            "-90.15402506253021 87\n",
            "False\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.23922888012080534\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.27843503011624193\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.28863659746599524\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.6098019124853407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.33566783282032\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.9137344130707787\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2593607696505842\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7190631829344567\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.6446664980850585\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3188695070176095\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.31451871597761283\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.33352614065964303\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.751658228468267\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.34853210860967465\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.37531650923307325\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4731982014494918\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.65543171261628\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.597089019417848\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.36370750803712326\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0449206620520897\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.43438544990343075\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.467709878858102\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5027910778625255\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8258411398769454\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5399098776613585\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5846756277204861\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.6112787369085027\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8322456123954112\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.6292841624904497\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7035352093416407\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3036523207106143\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7044657453008654\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.5207980564656736\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0619401644244817\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4739061220259941\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7777872871965315\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8123740931379757\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6099704662490808\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8636297629845444\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.358356302902405\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5535766440356498\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8920583697145616\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7468283597994856\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.0664315578665082\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.267597791537935\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9086140046894116\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9347249873225678\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9597830762921831\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4429278278259745\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.002731578511714\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2366423969717857\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.4961139432486332\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0245634229238476\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.0435877539425746\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.413736491915472\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9045289802964135\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1335709447726003\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1490674464753283\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6461961199939537\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.4846385698705715\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1271009705454844\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1383028835794562\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6836857795789455\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1525335459065786\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5797363244258122\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1766373066529354\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.1841965098143987\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3200751084321383\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4733991827034516\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2465714511529313\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.5839925444319194\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.303873829777865\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2485405209667988\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2547144202116556\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2603795202741708\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2656016983406744\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.951895754969928\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2806749651485916\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.286498063047759\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.599545593992957\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3321144340888509\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.538471039012461\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3646838577346898\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.91308320070616\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3458842180904185\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3567762384049615\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.406295890627348\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3612843041992733\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5808104542984893\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4369678319294508\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4546637138142842\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6712424744340297\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5317721387893357\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5547885270126471\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.761365124943052\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.589131889853718\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8784235485658314\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -3.2137472652986845\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.756347830231573\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.963096783122137\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7965746210747398\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.9698035137431473\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8684983319331536\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.2933023373318973\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.6904246257860107\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -2.0465054951818615\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -3.5508066649304055\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -100\n",
            "-261.1366431218055 108\n",
            "False\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.5753311199645623\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.898113646450696\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.11265798201519031\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.871628475287963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([28])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.681973521530216\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.5444272921705817\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.8825378364531673\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.829023845573687\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7752743526209258\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.7205084678816434\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.6649502861182555\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.608717817312396\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.5520515190189599\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4949398439650565\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.2445818116164218\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.4650403095921547\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.11521930115264353\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.3456758665981852\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.1729876644469812\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2827010773204108\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.2242357039412468\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.49311716584697934\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.814955830214649\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.5777967978532614\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.5942534392783216\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.4831825823310225\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -1.089511387442542\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.4998673037594243\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.276282911172541\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9964232556104662\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.311825812472017\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.8825665605664028\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9969432432401106\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.9392419061041153\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8813879560313751\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.8234087255731026\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.7119644357513835\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.8272171070972718\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.7053587098404819\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.647671036157135\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.9441024172292942\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.607895504696728\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.7368593925795153\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.2537608424589621\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.5156636010098055\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.0803706698409883\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.6966488599250056\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.1679531905102407\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.38619438008976203\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.670803845741517\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.30339500866418234\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.0390464915046436\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.25154080239013865\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.19831360855187086\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.14595380807827496\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.483922345433632\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.97176138665983\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.428233150393612\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.10440961028004381\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.06262245248854015\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.02534855018771509\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.005499465702399675\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  2.3488751831917796\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.02514559458700205\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.03652605455823732\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.0805978433431278\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.6481964844652226\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -0.3883599085565663\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  0.9284213578713377\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  1.8220422018350177\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  7.866810613153376\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  15.996070201873186\n",
            "action is: [[0, 0], 'Main off, Left Right off'] reward:  -100\n",
            "-62.63742686540274 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "BzyI3vKZQiR6",
        "outputId": "f26a671a-6a10-40c9-d760-f17453a47ab0"
      },
      "source": [
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"test\" autoplay \n",
              "                loop controls style=\"height: 400px;\">\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY_ve2aViqJa",
        "outputId": "e470154e-059f-4ddd-d308-8e7c20b0bcb3"
      },
      "source": [
        "print(iter)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQSL6GAC3Dw3",
        "outputId": "78b33f0e-3ea7-4ea2-ef4e-7423baa3a459"
      },
      "source": [
        "#Draw random samples from a normal (Gaussian) distribution.\n",
        "mu, sigma = 0, 0.05 # mean and standard deviation\n",
        "s = np.random.normal(mu, sigma, 1)\n",
        "print(s)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.03189281]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBtKRTtOdVID"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAcA1Rt_dVIE"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uDsuIXkdVIE"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}